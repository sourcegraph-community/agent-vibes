# Apify-Pipeline Konzept

## Zielsetzung
Die Pipeline sammelt regelmÃ¤ÃŸig Tweets rund um Coding-Agenten, normalisiert die Daten, analysiert Sentiments und stellt die Ergebnisse in einem gehosteten Dashboard bereit.

Architekturhinweis: Das Repository folgt einer Vertical Slice Architecture. Die komplette Pipeline lebt im Slice `src/ApifyPipeline`, der sowohl die Scheduler-AuftrÃ¤ge als auch die Next.js App-Router-OberflÃ¤che kapselt. API-Routen im Verzeichnis `app/api` importieren lediglich Slice-Endpunkte (REPR: Request â†’ Endpoint â†’ Handler â†’ Response DTO), sodass jede Ã„nderungen innerhalb des Slices bleiben.

## Ablauf auf hoher Ebene
1. **Trigger:** Ein Vercel Cron Job (Pro-Plan) ruft das interne Endpoint `/api/start-apify-run` auf, das anschlieÃŸend die Apify Run API anspricht. Die App-Router-Datei `app/api/start-apify-run/route.ts` re-exportiert dabei den Slice-Endpunkt `src/ApifyPipeline/Web/Application/Commands/StartApifyRun`. ZusÃ¤tzlich kÃ¶nnen manuelle DurchlÃ¤ufe angestoÃŸen werden.
2. **Datenerfassung (Apify Actor):** Der Actor nutzt entweder X API Pro-ZugÃ¤nge (â‰ˆâ€¯US$â€¯5â€¯k/Monat) oder den Apify Tweet Scraper; Letzterer unterliegt Anti-Monitoring-BeschrÃ¤nkungen, sodass Intervalle sorgfÃ¤ltig gedrosselt werden mÃ¼ssen.
3. **Vorverarbeitung:** Die rohen Tweets werden bereinigt, angereichert (z.â€¯B. Quelle, Zeitstempel, Plattform) und in ein einheitliches Format Ã¼berfÃ¼hrt.
4. **Persistenz (Supabase):** Normalisierte DatensÃ¤tze werden in Supabase gespeichert. Historische Werte bleiben erhalten und bilden die Grundlage fÃ¼r Analysen.
5. **Sentiment-Analyse (Gemini):** Geminiâ€¯2.5 klassifiziert Sentiments via Structured Output (keine dedizierte Sentiment-API) und speichert Ergebnisse zurÃ¼ck in Supabase; Kosten/TPS werden je nach Modellvariante (Flash, Flash Lite, Pro) Ã¼berwacht.
6. **Frontend (Vercel):** Eine Next.js-Anwendung visualisiert die Daten (Trends, Metriken, EinzeldatensÃ¤tze) und konsumiert ausschlieÃŸlich die Supabase-API.

## Komponenten & Verantwortlichkeiten
- **Apify Actor:** Datenerfassung, Normalisierung, Versand an Supabase â€“ wahlweise via X API (Pro-Tier) oder Apify Scraper mit regulatorischer Drosselung. (Slice: `src/ApifyPipeline/Background/Jobs/TweetCollector`)
- **Supabase:** Persistenzschicht (Tabellen fÃ¼r Rohdaten, normalisierte Tweets, Sentiment-Ergebnisse) mit `sb_secret_*` Keys und PG17-konformen Erweiterungen. (Slice: `src/ApifyPipeline/DataAccess`)
- **Google Gemini:** Structured-Output-Klassifikation Ã¼ber eine serverseitige Funktion oder einen Worker, der auf neue DatensÃ¤tze reagiert. (Slice: `src/ApifyPipeline/ExternalServices/Gemini`)
- **Next.js Frontend:** Darstellung der Statistiken, Filterungen, Trend-Erkennung; Build-Target Node.jsâ€¯20+ auf Vercel. (Slice: `src/ApifyPipeline/Web/Components/Dashboard`)
- **Vercel Cron:** Zeitgesteuertes AuslÃ¶sen des internen `/api/start-apify-run` Proxys. (Slice: `src/ApifyPipeline/Web/Application/Commands/StartApifyRun`)

> Hinweis: Supabase rotiert Secrets als `sb_secret_*`; Deployments mÃ¼ssen Service-Rollen-SchlÃ¼ssel regelmÃ¤ÃŸig erneuern und PG17-kompatible Erweiterungen wÃ¤hlen.
> Hinweis: Next.js-Builds auf Vercel laufen ab September 2025 ausschlieÃŸlich auf Node.jsâ€¯20+, Tests sollten die async Request APIs der App Router berÃ¼cksichtigen.

## Datenfluss (Mermaid)
```mermaid
graph TB
    %% Data Sources
    subgraph Sources [ğŸŒ Datenquellen]
        Twitter[ğŸ“¢ Twitter/X<br/>Coding-Agent Schlagworte]
    end

    %% Collection Layer
    subgraph Collection [ğŸ“¥ Datensammlung]
        AutoCron[â° Vercel Cron<br/>Automatische DurchlÃ¤ufe]
        ManualTrigger[ğŸ” Manuelle AuslÃ¶sung]
        Actor[ğŸ¤– Apify Actor
              <br/>Fetching & Normalisierung]
    end

    %% Processing & Intelligence
    subgraph Processing [ğŸ§  Verarbeitung]
        DataNorm[ğŸ“Š Daten-Normalisierung]
        Sentiment[ğŸ˜Š Sentiment Analyse]
        Insights[ğŸ’¡ Insights & Trends]
    end

    %% Storage
    subgraph Storage [ğŸ—„ï¸ Persistenz]
        Database[(ğŸ“š Supabase<br/>Tweets & Analysen)]
    end

    %% Frontend
    subgraph Frontend [ğŸŒ Web Anwendung]
        Analytics[ğŸ“ˆ Dashboard auf Vercel]
    end

    %% External Services
    subgraph External [â˜ï¸ Externe Dienste]
        Gemini[ğŸ¤– Gemini API]
        Vercel[âš¡ Vercel Hosting & Cron]
    end

    %% Main Data Flow
    Twitter --> Actor

    AutoCron --> Actor
    ManualTrigger --> Actor

    Actor --> DataNorm
    DataNorm --> Database
    DataNorm --> Sentiment

    Sentiment --> Gemini
    Gemini --> Database

    Database --> Insights
    Insights --> Analytics

    Vercel -.-> AutoCron
    Vercel -.-> Analytics

    classDef source fill:#1a365d,stroke:#3182ce,color:#ffffff
    classDef collect fill:#2d3748,stroke:#38b2ac,color:#ffffff
    classDef process fill:#2d3748,stroke:#9f7aea,color:#ffffff
    classDef storage fill:#2d3748,stroke:#e53e3e,color:#ffffff
    classDef frontend fill:#2d3748,stroke:#48bb78,color:#ffffff
    classDef external fill:#2d3748,stroke:#ed8936,color:#ffffff

    class Twitter source
    class AutoCron,ManualTrigger,Actor collect
    class DataNorm,Sentiment,Insights process
    class Database storage
    class Analytics frontend
    class Gemini,Vercel external
```

## Aktueller Status
- Supabase Basisschema inkl. Append-Only-Triggers und RLS-Policies liegt als Migration unter `src/ApifyPipeline/DataAccess/Migrations/20250929_1200_InitApifyPipeline.sql`.
- Views `vw_daily_sentiment` und `vw_keyword_trends` sind erstellt und liefern dank Seed-Daten (`src/ApifyPipeline/DataAccess/Seeds/20250929_1230_KeywordsSeed.sql`) Beispielmetriken fÃ¼r das Dashboard.
- Supabase Secret-Rotation lÃ¤uft Ã¼ber `npm run rotate:supabase` (TypeScript-Script [`scripts/rotate-supabase-secrets.ts`](file:///home/prinova/CodeProjects/agent-vibes/scripts/rotate-supabase-secrets.ts) nutzt Supabase Management API + Secrets Endpoint).
- Der Ingestion-Slice stellt `/api/start-apify-run` Ã¼ber `app/api/start-apify-run/route.ts` bereit und delegiert an `src/ApifyPipeline/Web/Application/Commands/StartApifyRun` + `Background/Jobs/TweetCollector`.
- Der Apify Actor unter `src/ApifyPipeline/Background/Jobs/TweetCollector/TweetCollectorJob.ts` holt Keywords aus Supabase, startet den Twitter-Scraper, schreibt `cron_runs`, `raw_tweets` und `normalized_tweets` und kennzeichnet Duplikate.

## Offene Punkte fÃ¼r spÃ¤tere Iterationen
- Fehlerbehandlung und Monitoring (Retries, Alerting) spezifizieren.
- Authentifizierung und Zugriffsfunktionen fÃ¼r Supabase und Apify festlegen.
- Kosten- und Latenzbetrachtung fÃ¼r Apify, Supabase und Gemini evaluieren.
- Integrationstests und Staging-Setup planen.
