# Apify-Pipeline Konzept

## Zielsetzung
Die Pipeline sammelt regelmÃ¤ÃŸig Tweets rund um Coding-Agenten, normalisiert die Daten, analysiert Sentiments und stellt die Ergebnisse in einem gehosteten Dashboard bereit.

## Ablauf auf hoher Ebene
1. **Trigger:** Ein Vercel Cron Job (Pro-Plan) ruft das interne Endpoint `/api/start-apify-run` auf, das anschlieÃŸend die Apify Run API anspricht. ZusÃ¤tzlich kÃ¶nnen manuelle DurchlÃ¤ufe angestoÃŸen werden.
2. **Datenerfassung (Apify Actor):** Der Actor nutzt entweder X API Pro-ZugÃ¤nge (â‰ˆâ€¯US$â€¯5â€¯k/Monat) oder den Apify Tweet Scraper; Letzterer unterliegt Anti-Monitoring-BeschrÃ¤nkungen, sodass Intervalle sorgfÃ¤ltig gedrosselt werden mÃ¼ssen.
3. **Vorverarbeitung:** Die rohen Tweets werden bereinigt, angereichert (z.â€¯B. Quelle, Zeitstempel, Plattform) und in ein einheitliches Format Ã¼berfÃ¼hrt.
4. **Persistenz (Supabase):** Normalisierte DatensÃ¤tze werden in Supabase gespeichert. Historische Werte bleiben erhalten und bilden die Grundlage fÃ¼r Analysen.
5. **Sentiment-Analyse (Gemini):** Geminiâ€¯2.5 klassifiziert Sentiments via Structured Output (keine dedizierte Sentiment-API) und speichert Ergebnisse zurÃ¼ck in Supabase; Kosten/TPS werden je nach Modellvariante (Flash, Flash Lite, Pro) Ã¼berwacht.
6. **Frontend (Vercel):** Eine Next.js-Anwendung visualisiert die Daten (Trends, Metriken, EinzeldatensÃ¤tze) und konsumiert ausschlieÃŸlich die Supabase-API.

## Komponenten & Verantwortlichkeiten
- **Apify Actor:** Datenerfassung, Normalisierung, Versand an Supabase â€“ wahlweise via X API (Pro-Tier) oder Apify Scraper mit regulatorischer Drosselung.
- **Supabase:** Persistenzschicht (Tabellen fÃ¼r Rohdaten, normalisierte Tweets, Sentiment-Ergebnisse) mit `sb_secret_*` Keys und PG17-konformen Erweiterungen.
- **Google Gemini:** Structured-Output-Klassifikation Ã¼ber eine serverseitige Funktion oder einen Worker, der auf neue DatensÃ¤tze reagiert.
- **Next.js Frontend:** Darstellung der Statistiken, Filterungen, Trend-Erkennung; Build-Target Node.jsâ€¯20+ auf Vercel.
- **Vercel Cron:** Zeitgesteuertes AuslÃ¶sen des internen `/api/start-apify-run` Proxys.

> Hinweis: Supabase rotiert Secrets als `sb_secret_*`; Deployments mÃ¼ssen Service-Rollen-SchlÃ¼ssel regelmÃ¤ÃŸig erneuern und PG17-kompatible Erweiterungen wÃ¤hlen.
> Hinweis: Next.js-Builds auf Vercel laufen ab September 2025 ausschlieÃŸlich auf Node.jsâ€¯20+, Tests sollten die async Request APIs der App Router berÃ¼cksichtigen.

## Datenfluss (Mermaid)
```mermaid
graph TB
    %% Data Sources
    subgraph Sources [ğŸŒ Datenquellen]
        Twitter[ğŸ“¢ Twitter/X<br/>Coding-Agent Schlagworte]
    end

    %% Collection Layer
    subgraph Collection [ğŸ“¥ Datensammlung]
        AutoCron[â° Vercel Cron<br/>Automatische DurchlÃ¤ufe]
        ManualTrigger[ğŸ” Manuelle AuslÃ¶sung]
        Actor[ğŸ¤– Apify Actor
              <br/>Fetching & Normalisierung]
    end

    %% Processing & Intelligence
    subgraph Processing [ğŸ§  Verarbeitung]
        DataNorm[ğŸ“Š Daten-Normalisierung]
        Sentiment[ğŸ˜Š Sentiment Analyse]
        Insights[ğŸ’¡ Insights & Trends]
    end

    %% Storage
    subgraph Storage [ğŸ—„ï¸ Persistenz]
        Database[(ğŸ“š Supabase<br/>Tweets & Analysen)]
    end

    %% Frontend
    subgraph Frontend [ğŸŒ Web Anwendung]
        Analytics[ğŸ“ˆ Dashboard auf Vercel]
    end

    %% External Services
    subgraph External [â˜ï¸ Externe Dienste]
        Gemini[ğŸ¤– Gemini API]
        Vercel[âš¡ Vercel Hosting & Cron]
    end

    %% Main Data Flow
    Twitter --> Actor

    AutoCron --> Actor
    ManualTrigger --> Actor

    Actor --> DataNorm
    DataNorm --> Database
    DataNorm --> Sentiment

    Sentiment --> Gemini
    Gemini --> Database

    Database --> Insights
    Insights --> Analytics

    Vercel -.-> AutoCron
    Vercel -.-> Analytics

    classDef source fill:#1a365d,stroke:#3182ce,color:#ffffff
    classDef collect fill:#2d3748,stroke:#38b2ac,color:#ffffff
    classDef process fill:#2d3748,stroke:#9f7aea,color:#ffffff
    classDef storage fill:#2d3748,stroke:#e53e3e,color:#ffffff
    classDef frontend fill:#2d3748,stroke:#48bb78,color:#ffffff
    classDef external fill:#2d3748,stroke:#ed8936,color:#ffffff

    class Twitter source
    class AutoCron,ManualTrigger,Actor collect
    class DataNorm,Sentiment,Insights process
    class Database storage
    class Analytics frontend
    class Gemini,Vercel external
```

## Offene Punkte fÃ¼r spÃ¤tere Iterationen
- Detailliertes Datenmodell (Tabellen, Schemata, Trigger) definieren.
- Fehlerbehandlung und Monitoring (Retries, Alerting) spezifizieren.
- Authentifizierung und Zugriffsfunktionen fÃ¼r Supabase und Apify festlegen.
- Kosten- und Latenzbetrachtung fÃ¼r Apify, Supabase und Gemini evaluieren.
- Integrationstests und Staging-Setup planen.
